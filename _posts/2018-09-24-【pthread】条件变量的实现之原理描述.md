---
layout:     page
title:      【pthread】条件变量的实现之原理描述
subtitle:   分析Glibc(2.27)中条件变量相关的代码
date:       2018-09-24
author:     翼
header-img: image/bg.jpg
catalog: true
tags:
---

## 前言
> 这是“条件变量的实现”系列的第一篇，总体描述条件变量实现原理。还有其他几篇会详细分析各个细节的实现。这几篇文章分析的Glibc版本都是 v2.27。

## POSIX标准对条件变量的描述
首先来看看，POSIX标准文档对 pthread_cond_wait 的描述，我列出了主要的几点：
1. pthread_cond_wait 应该阻塞在一个条件变量condvar上。应用程序应该保证调用这两个函数时传的参数 mutex 已经被调用线程获取（locked／acquired），否则会报错（对于PTHREAD_MUTEX_ERRORCHECK和robust的mutexes），或者结果可能是 **undefined behavior**（对于其他mutexes）。
2. pthread_cond_wait 会执行一个 **原子操作**（atomical operation）: 释放mutex，并且阻塞调用线程（release the mutex and block the calling thread on the condvar）。因为这个操作是原子的，所以当这个mutex被释放以后，如果有另一个线程获取到了这个mutex，并且调用了pthread_cond_broadcast()或者pthread_cond_signal()，这对前面那个释放mutex并阻塞的线程也会起作用。
3. 使用条件变量时，通常会同时配合使用一个Boolean类型的断言变量flag，如果为true，表示这个线程可以继续执行。然而，pthread_cond_wait() 可能会被**“伪”唤醒**。**也就是说，pthread_cond_wait()返回，并不表示flag为true或者为false。必须重新取flag的值来判断。**
4. 当一个线程用一个mutex调用 pthread_cond_wait()阻塞时（在等待条件变量condvar），这个 mutex 和 condvar 就被动态绑定起来，且这种绑定关系会一直存在，只要还有线程阻塞在这个condvar上。在此期间，如果有一个线程尝试用另外一个mutex来调用pthread_cond_wait()期待等待同一个condvar，那么就会导致 **undefined behavior**。当所有等待线程被唤醒（比如被一个pthread_cond_broadcast()），下一个使用mutex（可能跟前面那个不同）调用pthread_cond_wait()来等待那个condvar的操作，就会再次动态绑定这个mutex和condvar。也就是说，在一个线程调用pthread_cond_wait(condvar,mutex)阻塞在condvar上，到pthread_cond_wait返回或者执行cancellation cleanup这期间（就是线程被唤醒，但是还没有从pthread_cond_wait()返回），这个mutex和condvar的绑定关系可能会被移除或者替换。尽管如此，该线程也应该重新获取这个mutex，这是pthread_cond_wait做的最后一件事情，后面代码可以看到。
5. 一个线程等待一个condvar，那么也可以说这个线程处于一个 **cancellation point**。如果该线程的**cancelability**类型被设置为PTHREAD_CANCEL_DEFERRED，那么这个线程在响应一个取消请求时，就会先重新获取mutex，再调用第一个cancellation cleanup handler。效果上就好像这个线程被唤醒，可以执行到pthread_cond_wait()返回前，然后不返回，而是开始执行线程的取消活动，这包括执行取消清理函数。这一点是通过在阻塞线程之前调用__pthread_cleanup_push，把 __condvar_cleanup_waiting()添加到线程的清理函数列表中，并且 __condvar_cleanup_waiting() 是第一个被调用的清理函数。
6. 一个调用pthread_cond_wait()而阻塞的线程，如果被一个取消请求唤醒，它就应该不能再消费任何条件信号。
7. pthread_cond_timedwait()和 pthread_cond_wait()基本一样。但是如果是发生超时，而不是被条件信号唤醒，那情况稍有不同。pthread_cond_timedwait会释放mutex，并重新获取mutex，而且要消费一个条件信号。
8. 如果一个正在等待一个condvar的线程收到一个信号，当 **信号处理程序返回** 时，线程应该恢复到等待condvar的状态，就好像它从没被信号中断。另外，此时pthread_cond_wait也可能返回，这也属于前面说的“伪唤醒”。

## 条件变量的结构
条件变量是一个pthread_cond_t类型的结构体，起定义如下：
```cpp
typedef union
{
  struct __pthread_cond_s __data;
  char __size[__SIZEOF_PTHREAD_COND_T];
  __extension__ long long int __align;
} pthread_cond_t;

```
可见其主要结构是一个__pthread_cond_s结构体：
```cpp
/* Common definition of pthread_cond_t. */

struct __pthread_cond_s
{
  __extension__ union
  {
    __extension__ unsigned long long int __wseq;
    struct
    {
      unsigned int __low;
      unsigned int __high;
    } __wseq32;
  };
  __extension__ union
  {
    __extension__ unsigned long long int __g1_start;  // LSB is the index of current G2
    struct
    {
      unsigned int __low;
      unsigned int __high;
    } __g1_start32;
  };

  //__LOCK_ALIGNMENT: 
  
  //on all platforms,futexes are four-byte integers that must be aligned on a four-byte boundary.
  
  unsigned int __g_refs[2] __LOCK_ALIGNMENT;   //LSB is used as the futex_wake-request flag
  
  unsigned int __g_size[2];
  unsigned int __g1_orig_size;  //The 2 LSB are used as a condvar-internal lock.
  
  unsigned int __wrefs;
  unsigned int __g_signals[2];  //LSB is used as the group closed flag of each group
  
};

```

## 条件变量实现的算法描述
以下描述中会用到几个名词，先列出它们以及它们的意义。
1. condvar ： 一个条件变量。
2. waiter : 代指某个不特定的等待条件变量condvar的线程，一般指的是当前准备进入等待序列的线程。
3. waiters ：所有在等待条件变量condvar的线程，也可能指某个组中的所有等待线程。
4. signaler: 发送信号条件的线程，即调用 pthread_cond_signal()的线程。

首先，pthread_cond_signal, pthread_cond_broadcast, 和 pthread_cond_wait的三个原子操作 三者之间是happens-before关系。

### 等待序列 __wseq
每个等待线程waiter，都从条件变量condvar的__wseq(64 bits)中获得一个位置position。__wseq决定了哪些等待线程可以消费条件信号。

一个到达的条件信号，先以 **relaxed-MO** 取到 _wseq 的当前值（也就是下一个等待线程将获得的位置），只有位置比这个值小的等待线程可以消费这个信号。

虽然一个32bit值出现ABA问题的可能性很小，但是也不能忽略它的存在。因此实现中用一个64bit的counter(__wseq)来表示等待序列。在不支持64 bits 原子操作的平台上，这个等待序列会用更少的bits。

### futex (fast user-space mutual exclusion)
每个等待条件变量的线程开始都会自旋。如果只是让线程自旋，实现就能很简单了当。但是这个实现要用futex让线程阻塞。futex不能保证这些线程以FIFO顺序被唤醒。因此，实现时就不能只用一个futex来唤醒所有有资格的等待线程（eligible waiters）。

实现用了两个futex字：__g_signals[0] 和 __g_signals[1]。因为结构定义中加了对齐限制 **__LOCK_ALIGNMENT**，这几个int都是对齐的，因此__g_signals[0] 和 __g_signals[1] 就可以作为futex字使用（Glibc中定了一个两个宏 __LOCK_ALIGNMENT  和 __ONCE_ALIGNMENT，它们定义了线程数据结构内部的锁对齐的限制）。

一个等待线程获取自己在等待序列里面的位置，然后阻塞在一个futex上，这两个操作不是原子的。所以还需要这个futex字能可靠地通知等待线程它们已经signaled了，不要再试图阻塞。

条件变量相关的操作中，有多处用futex来实现锁机制。futex的好处是：可以用原子操作来改变锁的状态（futex字的值），内核不需要参与管理锁状态的过程。只有当需要阻塞或者唤醒线程/进程时，才需要进行系统调用，在用户态和内核态直接切换。这样实现的锁效率更高。

### G1 and G2
为了处理用于阻塞线程的futexes，实现维护着两组等待线程序列：
1. **G1** 这组由所有有资格消费条件信号的等待线程组成。进入的条件信号将一直signal G1这组的等待线程，直到G1的等待线程全部被signaled。
2. **G2** 当G1组还有等待线程没被signaled，新来的等待线程就被放入G2。当G1中所有的等待线程被signaled时，后面来的信号就会把G2变成新的G1，并且为后面的等待线程创建一个新的G2。

上面的条件变量结构体定义中，也能看到，有几个字段被定义成 **两个元素的数组**，例如__g_refs 和 __g_signals。表明它们都是与这两个组相关的。

条件变量是进程间共享的，因此我们不能分配新的内存，所以我们只是让两个组槽（slots of groups）在G1和G2之间切换角色。
每个组槽有以下几个部分组成：
1. 一个独立的futex字__g_signals[i]
2. 一系列可消费的信号__g_signals[i]。
3. 一个表示当前组中还未被signaled的信号的数目的__g_size[i]。
4. 一个引用计数__g_refs[i]。
组引用计数用于维护那些正在使用该组的futex的等待线程的数目，只有当这个引用计数为0时，这个组才能切换它的角色。这可以防止在这个futex字上出现ABA问题（**HOW？**）

为了表示这个组在等待线程序列中覆盖的间隔（包括哪个组槽包含G1或者G2），实现里面使用了一个64bit的counter(__g1_start)来指定G1的起始位置，用 waiter sequence counter（即__wseq）中的1个bit来表示当前哪个组槽包含G2（__wseq的LSB表示G2的索引，0或者1，看pthread_cond_t结构体的定义，也知道组槽总共就2个）。这允许我们 **原子地切换组的角色**（只需要切换__wseq的最低位）。

G1的起始位置使得一个waiter可以判断它们是否已经被完全signaled了（如果G1的起始位置比这个waiter的位置还靠后的话）。waiters无法判断当前它们在G1或者G2中，它们也没必要知道这一信息，因为waiters感兴趣的应该是是否有可用的信号，并且它们总是从G2开始（它们知道G2的组槽，因为等待序列__wseq中的LSB表示了这个信息）。

### 信号发送方 signaler
信号发送方signalers只是简单地填充正确的那个组，直到这个组中的所有等待线程全被signaled且该组可以被关闭了。（只有在不得不切换组角色的情况下，组的角色才会被切换，以便减少由于还有等待线程持有正在关闭的组G1的引用计数而不得不等待这些线程的可能性。）signalers还维护着G1的初始大小，从而可以得知G2的起始位置。signalers记录着一个组的剩余大小，当其中的等待线程取消等待（由于线程被取消，或者等待超时），它们会减少这个剩余大小。

### 字段解释
pthread_cond_t 由以下几个成员变量组成：

**__wseq**: waiter sequence counter  
1. LSB即为当前G2的索引
2. waiters 持有mutex时 fetch_add它。 信号发送方并发load/fetch_xor它。

为了实现条件变量的销毁（pthread_cond_destroy可能在所有等待线程被signaled时就被调用），等待线程在开始等待之前增加引用计数，在停止等待后，且在重新获取这个条件变量绑定的这个mutex之前，减少这个引用计数。

**__g1_start**: G1的起始位置  
1. LSB即为当前G2的索引
2. signalers获取到 condvar-internal lock 时会修改它，observed concurrently by waiters.

**__g1_orig_size**: G1的初始大小  
1. 两个 least-significant bits 表示 **condvar-internal lock**，因此实际的大小应该是：condvar.__data.__g1_orig_size >> 2。
2. 仅当获取到condvar-internal lock时才能访问这个字段。

**__wrefs**: Waiter reference counter  
1. 当等待线程移除了最后的那个引用时，如果它们应该调用futex_wake ，则 Bit 2 是true
2. Bit 1 是始终id （0 == CLOCK_REALTIME, 1 == CLOCK_MONOTONIC）
3. 当前条件变量是一个进程间共享的条件变量时，Bit 0 是true。见 __condvar_get_private(int flags)的实现。
4. 作为一个用于等待线程和pthread_cond_destroy的简单的引用计数。
5. 由上面4条得知，__wrefs的低 3 bits 做特殊用途，不属于引用计数。

两个组中的每个组，都有：  
**__g_refs**: Futex waiter reference count  
1. 当等待线程移除了最后的引用时，如果应该执行futex_wake，则 LSB = true
2. 引用计数，被等待线程和获取到 condvar-internal lock的信号发送方并发访问

**__g_signals**: 还能被消费的信号数目  
1. 被等待线程用作一个futex字，会被等待线程和信号发送方并发访问
2. 当前组的所有等待线程被signaled时（也就是该组将被关闭），LSB=true

**__g_size**： 当前组中剩余的等待线程（这些线程还没被signaled）  
1. 被信号发送方和取消等待的等待线程访问，两者均只能在获取到condvar-internal lock的情况下才能访问该字段
2. G2的大小一直是0，因为它的大小只有到G2切换为G1时才能得到。
3. 尽管这是一个unsigned类型，我们依赖unsigned溢出规则以便使这个字段存储有效的负值（特别地，当G2的等待线程取消等待时，__g_size［g2］会递减，于是就变为负数了）。

注意：

使用PTHREAD_COND_INITIALIZER初始化一个条件变量时，所有字段均会被初始化为0。即便如此，我们也不应该自己来初始化每个字段，而应该使用PTHREAD_COND_INITIALIZER。
这个初始化的结果是: 条件变量的G2的起始位置是0，G1是关闭的状态。

等待线程在获得__wseq的一个位置时不会要求一个组的所有权，仅仅只是在用futex来阻塞自己的时候增加这个组的引用计数。因此，有可能发生这种情况：一个组在一个等待线程增加引用计数之前就被关闭了。也就是说，等待线程必须要用__g1_start来检查是否他们的组已经关闭了，同时，在等待线程试图获取__g_signals中的信号而自旋的时候，也要进行这样的检查。

请注意：对于这样的检查，使用 relaxed MO 来 load __g1_start 足够（不需要更强的MO限制）。因为如果一个等待线程可以看到一个足够大的值，那它也可以消费等待线程组中的一个信号。

等待线程试图在没有持有引用计数的情况下，从__g_signals中取出一个信号，可能导致它们在自己的组已经关闭后从一个更新的组中偷出一个信号。它们并非总能够检查出是否发生偷信号的情况，因为它们不知道是什么时候偷的。但是它们可以保护性地给从中偷来信号的组送回一个信号，如果它们这么做了（并非必须的），就会发生“伪唤醒”（spurious wake up）。为了降低这种可能性，__g1_start也包含了当前G2的索引。等待线程可以用这个索引来检查这个组槽中是否存在别名，如果没有，它们不会从当前G1中偷出信号。这意味着，等待线程从中偷出信号的G1肯定已经被关闭了，它们不需要做任何修复的事情（fix anything）。

pthread_cond_t的最后一个字段是__g_signals[1]，这是必要的：以前的条件变量实现中，用了一个pointer-sized字段实现pthread_cond_t，所以初始化那种条件变量的PTHREAD_COND_INITIALIZER可能只把4个字节初始化为0，而不是我们现在需要的8个字节。在首次组角色切换之前（G2的起始位置还是0），__g_signals[1]不会被访问到，组角色切换将在一个无害的fetch-or（它的返回值被忽略）之后设置__g_signals[1]的值为0。这有效地完成了初始化的工作。

### 该实现的限制
1. 不允许超过 __PTHREAD_COND_MAX_GROUP_SIZE * (1 << 31) 个__pthread_cond_wait调用
2. 不允许超过__PTHREAD_COND_MAX_GROUP_SIZE个并发等待线程
3. 除了POSIX声明的可能的错误返回，这个实现还可能返回以下错误：
```
1. EPERM，当mutex是递归的，并且调用线程为拥有其所有权
2. OWNERDEAD 或 ENOTRECOVERABLE， 当使用robust mutex。不像其他的错误，这个错误可能在重新获取mutex时发生。这是不被POSIX允许的（POSIX要求所有的错误在释放mutex或者改变条件变量状态之前发生），但是实际上我们确实什么也做不了 
3. 当使用 PTHREAD_MUTEX_PP_* mutex时，我们可能返回__pthread_tpp_change_priority能返回的所有错误。这种情况下我们已经释放了mutex，调用者不能期望仍然有用mutex。

```

## 代码分析
这里关于 pthread_cond_wait 的讨论，同样适用于 pthread_cond_timedwait。先看看这两个函数的实现：

```cpp
/* See __pthread_cond_wait_common.  */
int __pthread_cond_wait (pthread_cond_t *cond, pthread_mutex_t *mutex)
{
  return __pthread_cond_wait_common (cond, mutex, NULL);
}

/* See __pthread_cond_wait_common.  */
int __pthread_cond_timedwait (pthread_cond_t *cond, pthread_mutex_t *mutex,
    const struct timespec *abstime)
{
  /* Check parameter validity.  This should also tell the compiler that
     it can assume that abstime is not NULL.  */
  if (abstime->tv_nsec < 0 || abstime->tv_nsec >= 1000000000)
    return EINVAL;
  return __pthread_cond_wait_common (cond, mutex, abstime);
}
```
从上面的代码来看，pthread_cond_wait 和 pthread_cond_timedwait 的实现是一模一样的，最终都是调用同一个函数 __pthread_cond_wait_common 来实现。因此，我们只需要分析 __pthread_cond_wait_common。简洁起见，后面就只说 pthread_cond_wait，不再提 pthread_cond_timedwait。


## __pthread_cond_wait_common 代码
```cpp
static __always_inline int
__pthread_cond_wait_common (pthread_cond_t * cond, pthread_mutex_t * mutex, const struct timespec * abstime) {
    const int maxspin = 0; 
    int err; 
    int result = 0; 
    LIBC_PROBE (cond_wait, 2, cond, mutex); 

    //原子操作从等待队列__wseq中获取一个position，并使等待队列加1(__wseq的最低位没有被用于等待队列，见下一行代码)

    uint64_t wseq = __condvar_fetch_add_wseq_acquire (cond, 2); 

    //最低位表示当前G2的索引（在条件变量中的几个二元数组的索引），线程总是进入G2

    unsigned int g = wseq & 1; 
    //seq才是真正的当前等待队列中的waiters数目，包括当前调用线程

    uint64_t seq = wseq >> 1; 

    //等待线程引用技术加1（__wrefs的低3位没有被用于引用计数）

    unsigned int flags = atomic_fetch_add_relaxed ( & cond - > __data.__wrefs, 8); 
    //返回条件变量类型：是进程私有的，还是进程间共享的

    int private = __condvar_get_private (flags); 

    //至此，当前调用线程已经注册为一个等待线程

    //release the mutex和block on the condvar必须是原子的；

    //因此，要在注册为一个等待线程之后才来释放这个mutex

    err = __pthread_mutex_unlock_usercnt (mutex, 0); 
    if (__glibc_unlikely (err != 0)) {
        __condvar_cancel_waiting (cond, seq, g, private); 
        __condvar_confirm_wakeup (cond, private); 
        return err; 
    }

    //获取当前组（G2）可被消费的信号数

    //内存顺序指定为 acquire ???

    unsigned int signals = atomic_load_acquire (cond - > __data.__g_signals + g); 
    do {
        while (1) {
            //若没有可消费的信号，就先开始一段自旋

            //这里没有判断是否已经超时就开始自旋，这可能会导致“伪唤醒”

            unsigned int spin = maxspin; 
            while (signals == 0 && spin > 0) {
                //当前等待线程的总数比G1的其事地址还小，说明G1已经被关闭

                if (seq < (__condvar_load_g1_start_relaxed (cond) >> 1))
                goto done; 
                signals = atomic_load_acquire (cond - > __data.__g_signals + g); 
                spin--; 
            }

            //__g_signals[i]最低位为true，表示当前组将被关闭

            if (signals & 1)
                goto done; 

            //如果当前组有可消费的信号，线程不阻塞，直接跳出while

            if (signals != 0)
                break; 

            //因自旋以后仍没有可消费的信号，开始准备阻塞线程

            //acquire mo ???

            //当前组引用计数加1（__g_refs最低位不用做引用计数）

            atomic_fetch_add_acquire (cond - > __data.__g_refs + g, 2); 
	  
            //再次判断当前组是否关闭 acquire/relaxed ???

            if (((atomic_load_acquire (cond - > __data.__g_signals + g) & 1) != 0) 
                || (seq < (__condvar_load_g1_start_relaxed (cond) >> 1))) {
                    __condvar_dec_grefs (cond, g, private); 
                    goto done; 
            }

            // Now block.

            struct _pthread_cleanup_buffer buffer; 
            struct _condvar_cleanup_buffer cbuffer; 
            cbuffer.wseq = wseq; 
            cbuffer.cond = cond; 
            cbuffer.mutex = mutex; 
            cbuffer.private = private; 
            
            //阻塞前，把__condvar_cleanup_waiting加入线程清理函数列表中

            //而且，__condvar_cleanup_waiting()将是第一个被调用的清理函数，由此保证了上面POSIX描述的第五点。

            __pthread_cleanup_push ( & buffer, __condvar_cleanup_waiting,  & cbuffer); 

            if (abstime == NULL) {
                //阻塞线程，不带超时设置

                err = futex_wait_cancelable (
                cond - > __data.__g_signals + g, 0, private); 
            }
            else {
                //阻塞线程，带超时设置

                if (__glibc_unlikely (abstime - > tv_sec < 0))
                    err = ETIMEDOUT; 
                    //超时采用 CLOCK_MONOTONIC 系统时钟

                else if ((flags & __PTHREAD_COND_CLOCK_MONOTONIC_MASK) != 0) {
                    struct timespec rt; 
                    if (__clock_gettime (CLOCK_MONOTONIC,  & rt) != 0)
                    __libc_fatal ("clock_gettime does not support "
                    "CLOCK_MONOTONIC"); 
                    //Convert the absolute timeout value to a relative timeout.

                    rt.tv_sec = abstime - > tv_sec - rt.tv_sec; 
                    rt.tv_nsec = abstime - > tv_nsec - rt.tv_nsec; 
                    if (rt.tv_nsec < 0) {
                        rt.tv_nsec + = 1000000000; // 1s--rt.tv_sec; 

                    }

                    //判断是否已经超时，现在使用相对时间了

                    if (__glibc_unlikely (rt.tv_sec < 0))
                        err = ETIMEDOUT; 
                    //阻塞线程，设置超时

                    else
                        err = futex_reltimed_wait_cancelable(cond - > __data.__g_signals + g, 0,  & rt, private); 
                }
                //超时采用 CLOCK_REALTIME 系统时钟

                else {
                    //阻塞线程，设置超时

                    err = futex_abstimed_wait_cancelable(cond - > __data.__g_signals + g, 0, abstime, private); 
                }
            }
	
            //移除清理函数，清理函数不会被调用

            _pthread_cleanup_pop ( & buffer, 0); 

            if (__glibc_unlikely (err == ETIMEDOUT)) {
                //减少引用计数，调用futex_wake唤醒线程

                __condvar_dec_grefs (cond, g, private); 

                //上面的 __condvar_dec_grefs 能避免死锁 ???

                __condvar_cancel_waiting (cond, seq, g, private); 
                esult = ETIMEDOUT; 
                goto done; 
            }
            else
            {
                //减少引用计数，调用futex_wake唤醒线程

                __condvar_dec_grefs (cond, g, private); 
            }
                
            //Reload signals

            signals = atomic_load_acquire (cond - > __data.__g_signals + g); 
        }
    }

    while ( ! atomic_compare_exchange_weak_acquire (cond - > __data.__g_signals + g,  & signals, signals - 2)); 

    int64_t g1_start = __condvar_load_g1_start_relaxed (cond); 
    if (seq < (g1_start >> 1)) {
        if (((g1_start & 1)^ 1) == g) {
            unsigned int s = atomic_load_relaxed (cond - > __data.__g_signals + g); 
            while (__condvar_load_g1_start_relaxed (cond) == g1_start) {
                if (((s & 1) != 0) || atomic_compare_exchange_weak_relaxed(cond - > __data.__g_signals + g,  & s, s + 2)) {
                    futex_wake (cond - > __data.__g_signals + g, 1, private); 
                    break; 
                }
              /* TODO Back off.  */

            }
        }
    }

done:
    __condvar_confirm_wakeup (cond, private); 
    /* Woken up; now re-acquire the mutex.  If this doesn't fail, return RESULT,
        which is set to ETIMEDOUT if a timeout occured, or zero otherwise.  */

    err = __pthread_mutex_cond_lock (mutex);
    /* XXX Abort on errors that are disallowed by POSIX?  */
    
    return (err != 0) ? err : result;
}

``` 

```cpp
int
__pthread_cond_signal (pthread_cond_t *cond)
{
    LIBC_PROBE (cond_signal, 1, cond);
    //relaxed mo:获取引用计数，检查是否有线程在等待 ???

    unsigned int wrefs = atomic_load_relaxed (&cond->__data.__wrefs);

    if (wrefs >> 3 == 0)
      return 0;
    int private = __condvar_get_private (wrefs);
    __condvar_acquire_lock (cond, private);
    
    //relaxed mo ???

    unsigned long long int wseq = __condvar_load_wseq_relaxed (cond);
    //__wseq的最低位是G2的索引

    unsigned int g1 = (wseq & 1) ^ 1;
    wseq >>= 1;
    bool do_futex_wake = false;

    //如果__g_size[g1]==0，则表示G2中有等待线程，__condvar_quiesce_and_switch_g1 会把G2切换成G1
    
    if ((cond->__data.__g_size[g1] != 0) || __condvar_quiesce_and_switch_g1 (cond, wseq, &g1, private))
    {
        //relaxed mo ??? 给G1中添加一个信号
        atomic_fetch_add_relaxed (cond->__data.__g_signals + g1, 2);
        
        //唤醒线程前，G1 waiters数目减1
        cond->__data.__g_size[g1]--;
        
        do_futex_wake = true;
    }
    __condvar_release_lock (cond, private);
    if (do_futex_wake)
      futex_wake (cond->__data.__g_signals + g1, 1, private);
    return 0;
}

/* This closes G1 (whose index is in G1INDEX), waits for all futex waiters to
   leave G1, converts G1 into a fresh G2, and then switches group roles so that
   the former G2 becomes the new G1 ending at the current __wseq value when we
   eventually make the switch (WSEQ is just an observation of __wseq by the
   signaler).
   If G2 is empty, it will not switch groups because then it would create an
   empty G1 which would require switching groups again on the next signal.
   Returns false iff groups were not switched because G2 was empty.  */
static bool __attribute__ ((unused))
__condvar_quiesce_and_switch_g1 (pthread_cond_t *cond, uint64_t wseq, unsigned int *g1index, int private)
{
    const unsigned int maxspin = 0;
    unsigned int g1 = *g1index;
    /* If there is no waiter in G2, we don't do anything.  The expression may
        look odd but remember that __g_size might hold a negative value, so
        putting the expression this way avoids relying on implementation-defined
        behavior.
        Note that this works correctly for a zero-initialized condvar too.  */
    unsigned int old_orig_size = __condvar_get_orig_size (cond);
    uint64_t old_g1_start = __condvar_load_g1_start_relaxed (cond) >> 1;
    if (((unsigned) (wseq - old_g1_start - old_orig_size) + cond->__data.__g_size[g1 ^ 1]) == 0)
        return false;
    /* Now try to close and quiesce G1.  We have to consider the following kinds
        of waiters:
        * Waiters from less recent groups than G1 are not affected because
        nothing will change for them apart from __g1_start getting larger.
        * New waiters arriving concurrently with the group switching will all go
        into G2 until we atomically make the switch.  Waiters existing in G2
        are not affected.
        * Waiters in G1 will be closed out immediately by setting a flag in
        __g_signals, which will prevent waiters from blocking using a futex on
        __g_signals and also notifies them that the group is closed.  As a
        result, they will eventually remove their group reference, allowing us
        to close switch group roles.  */
    /* First, set the closed flag on __g_signals.  This tells waiters that are
        about to wait that they shouldn't do that anymore.  This basically
        serves as an advance notificaton of the upcoming change to __g1_start;
        waiters interpret it as if __g1_start was larger than their waiter
        sequence position.  This allows us to change __g1_start after waiting
        for all existing waiters with group references to leave, which in turn
        makes recovery after stealing a signal simpler because it then can be
        skipped if __g1_start indicates that the group is closed (otherwise,
        we would have to recover always because waiters don't know how big their
        groups are).  Relaxed MO is fine.  */
    atomic_fetch_or_relaxed (cond->__data.__g_signals + g1, 1);
    /* Wait until there are no group references anymore.  The fetch-or operation
        injects us into the modification order of __g_refs; release MO ensures
        that waiters incrementing __g_refs after our fetch-or see the previous
        changes to __g_signals and to __g1_start that had to happen before we can
        switch this G1 and alias with an older group (we have two groups, so
        aliasing requires switching group roles twice).  Note that nobody else
        can have set the wake-request flag, so we do not have to act upon it.
        Also note that it is harmless if older waiters or waiters from this G1
        get a group reference after we have quiesced the group because it will
        remain closed for them either because of the closed flag in __g_signals
        or the later update to __g1_start.  New waiters will never arrive here
        but instead continue to go into the still current G2.  */
    unsigned r = atomic_fetch_or_release (cond->__data.__g_refs + g1, 0);
    while ((r >> 1) > 0)
    {
        for (unsigned int spin = maxspin; ((r >> 1) > 0) && (spin > 0); spin--)
        {
            /* TODO Back off.  */
            r = atomic_load_relaxed (cond->__data.__g_refs + g1);
        }
        if ((r >> 1) > 0)
        {
            /* There is still a waiter after spinning.  Set the wake-request
                flag and block.  Relaxed MO is fine because this is just about
                this futex word.  */
            r = atomic_fetch_or_relaxed (cond->__data.__g_refs + g1, 1);
            if ((r >> 1) > 0)
            futex_wait_simple (cond->__data.__g_refs + g1, r, private);
            /* Reload here so we eventually see the most recent value even if we
                do not spin.   */
            r = atomic_load_relaxed (cond->__data.__g_refs + g1);
        }
    }
    /* Acquire MO so that we synchronize with the release operation that waiters
        use to decrement __g_refs and thus happen after the waiters we waited
        for.  */
    atomic_thread_fence_acquire ();
    /* Update __g1_start, which finishes closing this group.  The value we add
        will never be negative because old_orig_size can only be zero when we
        switch groups the first time after a condvar was initialized, in which
        case G1 will be at index 1 and we will add a value of 1.  See above for
        why this takes place after waiting for quiescence of the group.
        Relaxed MO is fine because the change comes with no additional
        constraints that others would have to observe.  */
    __condvar_add_g1_start_relaxed (cond,
        (old_orig_size << 1) + (g1 == 1 ? 1 : - 1));
    /* Now reopen the group, thus enabling waiters to again block using the
        futex controlled by __g_signals.  Release MO so that observers that see
        no signals (and thus can block) also see the write __g1_start and thus
        that this is now a new group (see __pthread_cond_wait_common for the
        matching acquire MO loads).  */
    atomic_store_release (cond->__data.__g_signals + g1, 0);
    /* At this point, the old G1 is now a valid new G2 (but not in use yet).
        No old waiter can neither grab a signal nor acquire a reference without
        noticing that __g1_start is larger.
        We can now publish the group switch by flipping the G2 index in __wseq.
        Release MO so that this synchronizes with the acquire MO operation
        waiters use to obtain a position in the waiter sequence.  */
    wseq = __condvar_fetch_xor_wseq_release (cond, 1) >> 1;
    g1 ^= 1;
    *g1index ^= 1;
    /* These values are just observed by signalers, and thus protected by the
        lock.  */
    unsigned int orig_size = wseq - (old_g1_start + old_orig_size);
    __condvar_set_orig_size (cond, orig_size);
    /* Use and addition to not loose track of cancellations in what was
        previously G2.  */
    cond->__data.__g_size[g1] += orig_size;
    /* The new G1's size may be zero because of cancellations during its time
        as G2.  If this happens, there are no waiters that have to receive a
        signal, so we do not need to add any and return false.  */
    if (cond->__data.__g_size[g1] == 0)
    return false;
    return true;
}
```

## 实现分析

























































































